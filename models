import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    mean_absolute_error,
    mean_squared_error,
    r2_score
)


df = pd.read_csv('f1statistics.csv',delimiter=';')  # Замените путь на ваш файл

#  признаки и целевую переменную
X = df.drop(['num', 'racer', 'race', 'finish','points'], axis=1)  # Оставляем только признаки
y = df['finish']

#  данные на обучающую и тестовую выборки
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Функции для расчета и печати метрик
def evaluate_classification_model(model_name, y_true, y_pred):
    print(f"\n\n===== {model_name} =====")
    print(classification_report(y_true, y_pred))

    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion Matrix ({model_name})')
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.show()

    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred, average='weighted')
    rec = recall_score(y_true, y_pred, average='weighted')
    f1 = f1_score(y_true, y_pred, average='weighted')
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    r2 = r2_score(y_true, y_pred)

    print(f"Accuracy: {acc:.4f}")
    print(f"Precision: {prec:.4f}")
    print(f"Recall: {rec:.4f}")
    print(f"F1 Score: {f1:.4f}")
    print(f"Mean Absolute Error (MAE): {mae:.4f}")
    print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")
    print(f"R-squared (R^2): {r2:.4f}")


# 1. Логистическая регрессия
lr_model = LogisticRegression(max_iter=10000)
lr_model.fit(X_train, y_train)
predictions_lr = lr_model.predict(X_test)
evaluate_classification_model("Logistic Regression", y_test, predictions_lr)

coefficients = lr_model.coef_[0]

# Названия 
feature_names = list(X.columns)

#  график важности признаков
plt.figure(figsize=(10, 6))
plt.bar(feature_names, coefficients)
plt.xticks(rotation=90)
plt.xlabel('Признаки')
plt.ylabel('Коэффициенты')
plt.title('Веса признаков (логистическая регрессия)')
plt.show()

# 2. Случайный лес
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
predictions_rf = rf_model.predict(X_test)
evaluate_classification_model("Random Forest", y_test, predictions_rf)

#  важность признаков
importances_rf = rf_model.feature_importances_

# Сортируем признаки
sorted_idx = np.argsort(importances_rf)[::-1]


print("Важность признаков (случайный лес):")
for idx in sorted_idx:
    print(f"{feature_names[idx]} : {importances_rf[idx]:.4f}")

plt.figure(figsize=(10, 6))
plt.barh([feature_names[i] for i in sorted_idx], importances_rf[sorted_idx])
plt.xlabel('Важность признака')
plt.ylabel('Признак')
plt.title('Важность признаков (случайный лес)')
plt.show()

# 3. Градиентный бустинг
gb_model = GradientBoostingClassifier(random_state=42)
gb_model.fit(X_train, y_train)
predictions_gb = gb_model.predict(X_test)
evaluate_classification_model("Gradient Boosting", y_test, predictions_gb)\

#  важность признаков
importances_gb = gb_model.feature_importances_

# Сортируем
sorted_idx = np.argsort(importances_gb)[::-1]

print("Важность признаков (градиентный бустинг):")
for idx in sorted_idx:
    print(f"{feature_names[idx]} : {importances_gb[idx]:.4f}")

plt.figure(figsize=(10, 6))
plt.barh([feature_names[i] for i in sorted_idx], importances_gb[sorted_idx])
plt.xlabel('Важность признака')
plt.ylabel('Признак')
plt.title('Важность признаков (градиентный бустинг)')
plt.show()


